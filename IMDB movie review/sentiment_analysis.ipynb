{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c443bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a6806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"IMDB Dataset.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04609e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b22c6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a8e3a",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "1. Remove html tags\n",
    "2. Check if stop words are necessary if not remove them\n",
    "3. remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84648128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "    return clean_text\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fde632bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check if we need to remove stopwords or not\n",
    "#let's check with some commmon words which would be hugely significant in determining the sentiments of reviewrs.\n",
    "sentiment_words = [\"good\",\"bad\",\"worst\",\"lovely\",\"joyful\",\"happy\"]\n",
    "words_present = [word for word in sentiment_words if word in stopwords]\n",
    "print(words_present)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca994b",
   "metadata": {},
   "source": [
    "Looks like we can remove them safely them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b5cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation\n",
    "def remove_punctuations(s):\n",
    "    s = \"\".join([i for i in s if i not in string.punctuation])\n",
    "    return s\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(remove_punctuations)\n",
    "\n",
    "#Tokenizing into word tokens\n",
    "df[\"review\"] = df[\"review\"].apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acafce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words now\n",
    "def remove_stopwords(s):\n",
    "    s = \" \".join(each for each in s if each not in stopwords)\n",
    "    return s\n",
    "df[\"review\"] = df[\"review\"].apply(remove_stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a0c4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically theres family little boy Jake thinks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Matteis Love Time Money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One reviewers mentioned watching 1 Oz episode ...          1\n",
       "1  A wonderful little production The filming tech...          1\n",
       "2  I thought wonderful way spend time hot summer ...          1\n",
       "3  Basically theres family little boy Jake thinks...          0\n",
       "4  Petter Matteis Love Time Money visually stunni...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1dbd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numerical representation of labels\n",
    "def Convert_to_bin(text, remove_digits=True):\n",
    "  if text=='positive': \n",
    "      text= 1   \n",
    "  else: \n",
    "      text=0\n",
    "  return text\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(Convert_to_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c197c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into into train and test sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df['review'].values\n",
    "Y=df['sentiment'].values\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.3)\n",
    "\n",
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd1386",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting features using Count Vectorizer\n",
    "\n",
    "#\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_features = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "x_train =count_features\n",
    "x_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Convert your sparse input data to a correctly ordered sparse tensor\n",
    "\n",
    "\n",
    "model.fit(X_train_sparse, Y_train, batch_size=32, epochs=10, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80aa27d",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03861383",
   "metadata": {},
   "source": [
    "## Traning your own Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54157c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train) #Fitting a tokenizer on the corpus by considering 10,000 as size of vocavulary but keeping first 10,000 words in a sorted words according to their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04161a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing each sentence with the words numerical representation by considering only first 10000 words.\n",
    "x_train = tokenizer.texts_to_sequences(X_train)\n",
    "x_test  = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dcc8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are padding all sentences to a length of max length 100.\n",
    "vocab = len(tokenizer.word_index) + 1\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2508f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense, Activation, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "emb_dim=100\n",
    "model= Sequential()\n",
    "model.add(Embedding(input_dim=vocab, output_dim=emb_dim, input_length=maxlen))\n",
    "model.add(MaxPool1D())\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f392435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          17745600  \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 50, 100)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50, 16)            1616      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50, 16)            272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50, 1)             17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,747,505\n",
      "Trainable params: 17,747,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efaa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "2188/2188 [==============================] - 362s 165ms/step - loss: 0.6630 - accuracy: 0.5843\n",
      "Epoch 2/35\n",
      "2188/2188 [==============================] - 358s 164ms/step - loss: 0.6499 - accuracy: 0.6024\n",
      "Epoch 3/35\n",
      "2188/2188 [==============================] - 378s 173ms/step - loss: 0.6431 - accuracy: 0.6101\n",
      "Epoch 4/35\n",
      "2188/2188 [==============================] - 377s 172ms/step - loss: 0.6349 - accuracy: 0.6183\n",
      "Epoch 5/35\n",
      "2188/2188 [==============================] - 381s 174ms/step - loss: 0.6238 - accuracy: 0.6288\n",
      "Epoch 6/35\n",
      "2188/2188 [==============================] - 634s 290ms/step - loss: 0.6107 - accuracy: 0.6391\n",
      "Epoch 7/35\n",
      "2188/2188 [==============================] - 401s 183ms/step - loss: 0.5967 - accuracy: 0.6497\n",
      "Epoch 8/35\n",
      "2188/2188 [==============================] - 407s 186ms/step - loss: 0.5830 - accuracy: 0.6588\n",
      "Epoch 9/35\n",
      "2188/2188 [==============================] - 398s 182ms/step - loss: 0.5708 - accuracy: 0.6660\n",
      "Epoch 10/35\n",
      "2188/2188 [==============================] - 409s 187ms/step - loss: 0.5603 - accuracy: 0.6723\n",
      "Epoch 11/35\n",
      "2188/2188 [==============================] - 377s 172ms/step - loss: 0.5509 - accuracy: 0.6776\n",
      "Epoch 12/35\n",
      "2188/2188 [==============================] - 356s 163ms/step - loss: 0.5435 - accuracy: 0.6816\n",
      "Epoch 13/35\n",
      "2188/2188 [==============================] - 2330s 1s/step - loss: 0.5365 - accuracy: 0.6852\n",
      "Epoch 14/35\n",
      "2188/2188 [==============================] - 9616s 4s/step - loss: 0.5303 - accuracy: 0.6886\n",
      "Epoch 15/35\n",
      "1390/2188 [==================>...........] - ETA: 2:15 - loss: 0.5206 - accuracy: 0.6944"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, Y_train,epochs=35,verbose=True,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100055e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/a-guide-to-text-classification-and-sentiment-analysis-2ab021796317 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1723c221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a62f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368ed21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b70615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1024ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65ba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0927a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264897e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2063b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
